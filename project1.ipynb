{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d874cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in d:\\day2_ai\\ai_bootcamp\\lib\\site-packages (from opencv-python) (2.2.6)\n",
      "Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.12.0.88\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64ca328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.layers import Input, Lambda ,Dense ,Flatten ,Dropout\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "train_dir = \"/kaggle/input/american-sign-language-recognition/training_set\"\n",
    "eval_dir = \"/kaggle/input/american-sign-language-recognition/test_set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8112e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to load images from given directories\n",
    "def load_images(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for idx, label in enumerate(uniq_labels):\n",
    "        for file in os.listdir(directory + \"/\" + label):\n",
    "            filepath = directory + \"/\" + label + \"/\" + file\n",
    "            image = cv2.resize(cv2.imread(filepath), (64, 64))\n",
    "            images.append(image)\n",
    "            labels.append(idx)\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b512d3aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/kaggle/input/american-sign-language-recognition/training_set'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m uniq_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      4\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m load_images(directory \u001b[38;5;241m=\u001b[39m train_dir)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m uniq_labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(eval_dir)):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/kaggle/input/american-sign-language-recognition/training_set'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "uniq_labels = sorted(os.listdir(train_dir))\n",
    "images, labels = load_images(directory = train_dir)\n",
    "\n",
    "if uniq_labels == sorted(os.listdir(eval_dir)):\n",
    "    X_eval, y_eval = load_images(directory = eval_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f5de8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size = 0.2, stratify = labels)\n",
    "\n",
    "n = len(uniq_labels)\n",
    "train_n = len(X_train)\n",
    "test_n = len(X_test)\n",
    "\n",
    "print(\"Total number of symbols: \", n)\n",
    "print(\"Number of training images: \" , train_n)\n",
    "print(\"Number of testing images: \", test_n)\n",
    "\n",
    "eval_n = len(X_eval)\n",
    "print(\"Number of evaluation images: \", eval_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef74ef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd707d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "y_eval = keras.utils.to_categorical(y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf684f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[0])\n",
    "print(len(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bad577",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')/255.0\n",
    "X_test = X_test.astype('float32')/255.0\n",
    "X_eval = X_eval.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32af72e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_vgg16 = VGG16(input_shape= (64,64,3),include_top=False,weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac6d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising vgg16 \n",
    "classifier_resnet = ResNet50(input_shape= (64,64,3),include_top=False,weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699e40ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't train existing weights for vgg16\n",
    "for layer in classifier_vgg16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#don't train existing weights for resnet50\n",
    "for layer in classifier_resnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e58a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier1 = classifier_vgg16.output#head mode\n",
    "classifier1 = Flatten()(classifier1)#adding layer of flatten\n",
    "classifier1 = Dense(units=256, activation='relu')(classifier1)\n",
    "classifier1 = Dropout(0.6)(classifier1)\n",
    "classifier1 = Dense(units=40, activation='softmax')(classifier1)\n",
    "\n",
    "model = Model(inputs = classifier_vgg16.input , outputs = classifier1)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c413b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2 = classifier_resnet.output#head mode\n",
    "classifier2 = Flatten()(classifier2)#adding layer of flatten\n",
    "classifier2 = Dropout(0.6)(classifier2)\n",
    "classifier2 = Dense(units=40, activation='softmax')(classifier2)\n",
    "\n",
    "model2 = Model(inputs = classifier_resnet.input , outputs = classifier2)\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b6bd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59c0b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f19b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "#it will take some time to train\n",
    "history2 = model2.fit(X_train, y_train, epochs =5, batch_size = 64,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c22eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model of vgg16\n",
    "model.save('model_vgg16.h5')\n",
    "# Saving the model of resnet\n",
    "model2.save('model_resnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb06813",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x = X_test, y = y_test, verbose = 0)\n",
    "print('Accuracy for test images:', round(score[1]*100, 3), '%')\n",
    "score = model.evaluate(x = X_eval, y = y_eval, verbose = 0)\n",
    "print('Accuracy for evaluation images:', round(score[1]*100, 3), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4067905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model2.evaluate(x = X_test, y = y_test, verbose = 0)\n",
    "print('Accuracy for test images:', round(score[1]*100, 3), '%')\n",
    "score = model2.evaluate(x = X_eval, y = y_eval, verbose = 0)\n",
    "print('Accuracy for evaluation images:', round(score[1]*100, 3), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a903ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to plot confusion matrix\n",
    "def plot_confusion_matrix(y, y_pred):\n",
    "    y = np.argmax(y, axis = 1)\n",
    "    y_pred = np.argmax(y_pred, axis = 1)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    plt.figure(figsize = (24, 20))\n",
    "    ax = plt.subplot()\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = plt.cm.Purples)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    tick_marks = np.arange(len(uniq_labels))\n",
    "    plt.xticks(tick_marks, uniq_labels, rotation=45)\n",
    "    plt.yticks(tick_marks, uniq_labels)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    ax.title.set_fontsize(20)\n",
    "    ax.xaxis.label.set_fontsize(16)\n",
    "    ax.yaxis.label.set_fontsize(16)\n",
    "    limit = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment = \"center\",color = \"white\" if cm[i, j] > limit else \"black\")\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "y_test_pred = model.predict(X_test, batch_size = 64, verbose = 0)\n",
    "plot_confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46021e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval_pred = model.predict(X_eval, batch_size = 512,verbose = 0)\n",
    "plot_confusion_matrix(y_eval, y_eval_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8523f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y, y_pred):\n",
    "    y = np.argmax(y, axis = 1)\n",
    "    y_pred = np.argmax(y_pred, axis = 1)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    plt.figure(figsize = (24, 20))\n",
    "    ax = plt.subplot()\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = plt.cm.Purples)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    tick_marks = np.arange(len(uniq_labels))\n",
    "    plt.xticks(tick_marks, uniq_labels, rotation=45)\n",
    "    plt.yticks(tick_marks, uniq_labels)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    ax.title.set_fontsize(20)\n",
    "    ax.xaxis.label.set_fontsize(16)\n",
    "    ax.yaxis.label.set_fontsize(16)\n",
    "    limit = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment = \"center\",color = \"white\" if cm[i, j] > limit else \"black\")\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "y_test_pred = model2.predict(X_test, batch_size = 64, verbose = 0)\n",
    "plot_confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf68f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval_pred = model2.predict(X_eval, batch_size = 64, verbose = 0)\n",
    "plot_confusion_matrix(y_eval, y_eval_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5807bdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('/kaggle/input/american-sign-language-recognition/test_set/best of luck/11.png',target_size=(64,64))\n",
    "plt.imshow(test_image)\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = model.predict(test_image)\n",
    "\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    prediction = '1'\n",
    "elif result[0][1] == 1:\n",
    "    prediction = '10'\n",
    "elif result[0][2] == 1:\n",
    "    prediction = '2'\n",
    "elif result[0][3] == 1:\n",
    "    prediction = '3'\n",
    "elif result[0][4] == 1:\n",
    "    prediction = '4'\n",
    "elif result[0][5] == 1:\n",
    "    prediction = '5'\n",
    "elif result[0][6] == 1:\n",
    "    prediction = '6'\n",
    "elif result[0][7] == 1:\n",
    "    prediction = '7'\n",
    "elif result[0][8] == 1:\n",
    "    prediction = '8'\n",
    "elif result[0][9] == 1:\n",
    "    prediction = '9'\n",
    "elif result[0][10] == 1:\n",
    "    prediction = 'A'\n",
    "elif result[0][11] == 1:\n",
    "    prediction = 'B'\n",
    "elif result[0][12] == 1:\n",
    "    prediction = 'C'\n",
    "elif result[0][13] == 1:\n",
    "    prediction = 'D'\n",
    "elif result[0][14] == 1:\n",
    "    prediction = 'E'\n",
    "elif result[0][15] == 1:\n",
    "    prediction = 'F'\n",
    "elif result[0][16] == 1:\n",
    "    prediction = 'G'\n",
    "elif result[0][17] == 1:\n",
    "    prediction = 'H'\n",
    "elif result[0][18] == 1:\n",
    "    prediction = 'I'\n",
    "elif result[0][19] == 1:\n",
    "    prediction = 'J'\n",
    "elif result[0][20] == 1:\n",
    "    prediction = 'K'\n",
    "elif result[0][21] == 1:\n",
    "    prediction = 'L'\n",
    "elif result[0][22] == 1:\n",
    "    prediction = 'M'\n",
    "elif result[0][23] == 1:\n",
    "    prediction = 'N'\n",
    "elif result[0][24] == 1:\n",
    "    prediction = 'O'\n",
    "elif result[0][25] == 1:\n",
    "    prediction = 'P'\n",
    "elif result[0][26] == 1:\n",
    "    prediction = 'Q'\n",
    "elif result[0][27] == 1:\n",
    "    prediction = 'R'\n",
    "elif result[0][28] == 1:\n",
    "    prediction = 'S'\n",
    "elif result[0][29] == 1:\n",
    "    prediction = 'T'\n",
    "elif result[0][30] == 1:\n",
    "    prediction = 'U'\n",
    "elif result[0][31] == 1:\n",
    "    prediction = 'V'\n",
    "elif result[0][32] == 1:\n",
    "    prediction = 'W'\n",
    "elif result[0][33] == 1:\n",
    "    prediction = 'X'\n",
    "elif result[0][34] == 1:\n",
    "    prediction = 'Y'\n",
    "elif result[0][35] == 1:\n",
    "    prediction = 'Z'\n",
    "elif result[0][36] == 1:\n",
    "    prediction = 'best of luck'\n",
    "elif result[0][38] == 1:\n",
    "    prediction = 'i love you'\n",
    "else:\n",
    "    prediction = '  '\n",
    "    \n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
